{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OMOP to MEDS ETL Process\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook documents the ETL (Extract, Transform, Load) process used to convert OMOP Common Data Model format to Medical Event Data Standard (MEDS) format.\n",
    "\n",
    "### What Was Done\n",
    "\n",
    "The ETL process consisted of four main phases:\n",
    "\n",
    "1. **Extraction**: Load cleaned OMOP tables and concept mappings\n",
    "2. **Transformation**: Convert OMOP structure to MEDS time-series format\n",
    "3. **Temporal Alignment**: Align event times to visit start times\n",
    "4. **Validation and Cleaning**: Apply temporal consistency checks\n",
    "\n",
    "### MEDS Format\n",
    "\n",
    "MEDS represents medical data as time-series events with:\n",
    "- `PERSON_ID`: Patient identifier\n",
    "- `time`: Event timestamp (aligned to visit start)\n",
    "- `code`: Medical code in VOCABULARY/CODE format\n",
    "- `numeric_value`: Numeric measurements (for lab results)\n",
    "- `datetime_value`: Original event datetime\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import StructType, StructField, StringType, TimestampType, FloatType\n",
    "import logging\n",
    "from typing import Dict, List\n",
    "\n",
    "# Initialize Spark\n",
    "spark = SparkSession.builder.appName(\"OMOP_to_MEDS_ETL\").getOrCreate()\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define MEDS Schema\n",
    "\n",
    "The MEDS schema standardizes how medical events are represented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meds_schema():\n",
    "    \"\"\"Define the MEDS data schema.\"\"\"\n",
    "    return StructType([\n",
    "        StructField(\"PERSON_ID\", StringType(), True),\n",
    "        StructField(\"time\", TimestampType(), True),\n",
    "        StructField(\"datetime_value\", TimestampType(), True),\n",
    "        StructField(\"code\", StringType(), True),\n",
    "        StructField(\"numeric_value\", FloatType(), True)\n",
    "    ])\n",
    "\n",
    "MEDS_SCHEMA = get_meds_schema()\n",
    "print(\"MEDS schema defined\")\n",
    "print(MEDS_SCHEMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configuration\n",
    "\n",
    "Define which OMOP tables to process and required columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths (MODIFY THESE)\n",
    "CLEANED_OMOP_PATH = \"/path/to/your/cleaned/omop/data/\"\n",
    "CONCEPT_PATH = \"/path/to/your/raw/omop/data/concept\"\n",
    "OUTPUT_PATH = \"/path/to/your/meds/output/\"\n",
    "\n",
    "# Tables and required columns\n",
    "OMOP_TABLES = {\n",
    "    \"person\": [\n",
    "        \"PERSON_ID\", \"YEAR_OF_BIRTH\", \"MONTH_OF_BIRTH\", \n",
    "        \"DAY_OF_BIRTH\", \"BIRTH_DATETIME\"\n",
    "    ],\n",
    "    \"visit_occurrence\": [\n",
    "        \"PERSON_ID\", \"VISIT_CONCEPT_ID\", \"VISIT_OCCURRENCE_ID\", \n",
    "        \"VISIT_START_DATETIME\"\n",
    "    ],\n",
    "    \"condition_occurrence\": [\n",
    "        \"PERSON_ID\", \"CONDITION_CONCEPT_ID\", \n",
    "        \"CONDITION_START_DATETIME\", \"VISIT_OCCURRENCE_ID\"\n",
    "    ],\n",
    "    \"drug_exposure\": [\n",
    "        \"PERSON_ID\", \"DRUG_CONCEPT_ID\", \n",
    "        \"DRUG_EXPOSURE_START_DATETIME\", \"VISIT_OCCURRENCE_ID\"\n",
    "    ],\n",
    "    \"procedure_occurrence\": [\n",
    "        \"PERSON_ID\", \"PROCEDURE_CONCEPT_ID\", \n",
    "        \"PROCEDURE_DATETIME\", \"VISIT_OCCURRENCE_ID\"\n",
    "    ],\n",
    "    \"measurement\": [\n",
    "        \"PERSON_ID\", \"MEASUREMENT_CONCEPT_ID\", \"MEASUREMENT_DATETIME\", \n",
    "        \"VALUE_AS_NUMBER\", \"VISIT_OCCURRENCE_ID\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(f\"Configured to process {len(OMOP_TABLES)} tables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extract: Load OMOP Data\n",
    "\n",
    "Load cleaned OMOP tables and the concept vocabulary for code mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_omop_tables() -> Dict[str, DataFrame]:\n",
    "    \"\"\"Load OMOP tables from Parquet files.\"\"\"\n",
    "    tables = {}\n",
    "    \n",
    "    for table_name, columns in OMOP_TABLES.items():\n",
    "        try:\n",
    "            df = spark.read.parquet(f\"{CLEANED_OMOP_PATH}{table_name}\")\n",
    "            tables[table_name] = df.select(*columns)\n",
    "            logger.info(f\"Loaded {table_name}: {df.count():,} records\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading {table_name}: {str(e)}\")\n",
    "    \n",
    "    return tables\n",
    "\n",
    "print(\"Loading OMOP tables...\")\n",
    "omop_tables = load_omop_tables()\n",
    "print(f\"\\nLoaded {len(omop_tables)} tables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Concept Mappings\n",
    "\n",
    "Map OMOP concept IDs to VOCABULARY/CODE format used in MEDS.\n",
    "\n",
    "Example: Concept ID 313217 â†’ \"SNOMED/38341003\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_concept_map() -> Dict[str, str]:\n",
    "    \"\"\"Create mapping from concept IDs to vocabulary codes.\"\"\"\n",
    "    concept_df = spark.read.parquet(CONCEPT_PATH)\n",
    "    \n",
    "    # Select required columns\n",
    "    concept_df = concept_df.select(\n",
    "        \"CONCEPT_ID\", \n",
    "        \"VOCABULARY_ID\", \n",
    "        \"CONCEPT_CODE\"\n",
    "    )\n",
    "    \n",
    "    # Create code in format: VOCABULARY/CODE\n",
    "    concept_df = concept_df.withColumn(\n",
    "        \"code\",\n",
    "        F.concat_ws(\"/\", F.col(\"VOCABULARY_ID\"), F.col(\"CONCEPT_CODE\"))\n",
    "    )\n",
    "    \n",
    "    # Convert to dictionary\n",
    "    concept_map = dict(\n",
    "        concept_df.select(\"CONCEPT_ID\", \"code\")\n",
    "                  .rdd\n",
    "                  .collectAsMap()\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"Created concept map with {len(concept_map):,} entries\")\n",
    "    return concept_map\n",
    "\n",
    "print(\"Creating concept mappings...\")\n",
    "concept_map = create_concept_map()\n",
    "print(f\"Concept map created with {len(concept_map):,} mappings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Transform: Person Table\n",
    "\n",
    "Convert person demographics to MEDS birth events.\n",
    "\n",
    "### Transformation Logic:\n",
    "- Construct birth date from YEAR/MONTH/DAY components\n",
    "- Assign birth event code: SNOMED/184099003 (Live birth)\n",
    "- Set time = birth date\n",
    "- Set datetime_value = BIRTH_DATETIME if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_person(person_df: DataFrame) -> DataFrame:\n",
    "    \"\"\"Transform person table to MEDS birth events.\"\"\"\n",
    "    # Filter valid records\n",
    "    df = person_df.filter(F.col(\"YEAR_OF_BIRTH\").isNotNull())\n",
    "    \n",
    "    # Create birth datetime from components\n",
    "    df = df.withColumn(\n",
    "        \"time\",\n",
    "        F.to_timestamp(\n",
    "            F.concat_ws(\n",
    "                '-',\n",
    "                F.col(\"YEAR_OF_BIRTH\"),\n",
    "                F.lpad(F.coalesce(F.col(\"MONTH_OF_BIRTH\"), F.lit(1)), 2, '0'),\n",
    "                F.lpad(F.coalesce(F.col(\"DAY_OF_BIRTH\"), F.lit(1)), 2, '0')\n",
    "            ),\n",
    "            \"yyyy-MM-dd\"\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Set datetime_value\n",
    "    df = df.withColumn(\"datetime_value\", F.col(\"BIRTH_DATETIME\").cast(\"timestamp\"))\n",
    "    \n",
    "    # Birth event code (SNOMED: Live birth)\n",
    "    df = df.withColumn(\"code\", F.lit(\"SNOMED/184099003\"))\n",
    "    \n",
    "    # No numeric value for birth\n",
    "    df = df.withColumn(\"numeric_value\", F.lit(None).cast(\"float\"))\n",
    "    \n",
    "    # Select MEDS columns\n",
    "    return df.select(\"PERSON_ID\", \"time\", \"datetime_value\", \"code\", \"numeric_value\")\n",
    "\n",
    "print(\"Transforming person table...\")\n",
    "person_meds = transform_person(omop_tables['person'])\n",
    "print(f\"Transformed person: {person_meds.count():,} birth events\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Transform: Clinical Event Tables\n",
    "\n",
    "Convert clinical events (conditions, drugs, procedures, measurements) to MEDS format.\n",
    "\n",
    "### Key Transformations:\n",
    "\n",
    "1. **Time Alignment**: Join with visit_occurrence to get visit start time\n",
    "   - `time` = visit start datetime (for temporal alignment)\n",
    "   - `datetime_value` = original event datetime (for reference)\n",
    "\n",
    "2. **Code Mapping**: Map concept IDs to vocabulary codes\n",
    "   - Look up concept ID in concept_map\n",
    "   - Convert to VOCABULARY/CODE format\n",
    "\n",
    "3. **Numeric Values**: Extract measurement values\n",
    "   - For measurement table: use VALUE_AS_NUMBER\n",
    "   - For other tables: set to null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_clinical_table(\n",
    "    df: DataFrame,\n",
    "    table_name: str,\n",
    "    visit_df: DataFrame,\n",
    "    concept_map_dict: Dict[str, str]\n",
    ") -> DataFrame:\n",
    "    \"\"\"Transform clinical event table to MEDS format.\"\"\"\n",
    "    \n",
    "    # Join with visit to get visit start time\n",
    "    if \"VISIT_OCCURRENCE_ID\" in df.columns:\n",
    "        visit_times = visit_df.select(\n",
    "            \"VISIT_OCCURRENCE_ID\",\n",
    "            F.col(\"VISIT_START_DATETIME\").alias(\"visit_start_time\")\n",
    "        )\n",
    "        df = df.join(visit_times, on=\"VISIT_OCCURRENCE_ID\", how=\"left\")\n",
    "        df = df.withColumn(\"time\", F.col(\"visit_start_time\").cast(\"timestamp\"))\n",
    "    else:\n",
    "        df = df.withColumn(\"time\", F.lit(None).cast(\"timestamp\"))\n",
    "    \n",
    "    # Get original datetime\n",
    "    datetime_cols = [col for col in df.columns if \"_DATETIME\" in col]\n",
    "    if datetime_cols:\n",
    "        datetime_value = F.col(datetime_cols[0]).cast(\"timestamp\")\n",
    "        for col_name in datetime_cols[1:]:\n",
    "            datetime_value = F.coalesce(datetime_value, F.col(col_name).cast(\"timestamp\"))\n",
    "        df = df.withColumn(\"datetime_value\", datetime_value)\n",
    "    else:\n",
    "        df = df.withColumn(\"datetime_value\", F.lit(None).cast(\"timestamp\"))\n",
    "    \n",
    "    # Map concept IDs to codes\n",
    "    concept_col = next(col for col in df.columns if \"CONCEPT_ID\" in col and col != \"VISIT_OCCURRENCE_ID\")\n",
    "    \n",
    "    concept_map_df = spark.createDataFrame(\n",
    "        [(k, v) for k, v in concept_map_dict.items()],\n",
    "        [\"concept_id\", \"code\"]\n",
    "    )\n",
    "    \n",
    "    df = df.join(\n",
    "        F.broadcast(concept_map_df),\n",
    "        df[concept_col] == concept_map_df[\"concept_id\"],\n",
    "        \"left\"\n",
    "    )\n",
    "    \n",
    "    # Handle numeric values\n",
    "    if table_name == \"measurement\":\n",
    "        df = df.withColumn(\"numeric_value\", F.col(\"VALUE_AS_NUMBER\").cast(\"float\"))\n",
    "    else:\n",
    "        df = df.withColumn(\"numeric_value\", F.lit(None).cast(\"float\"))\n",
    "    \n",
    "    # Select MEDS columns\n",
    "    return df.select(\"PERSON_ID\", \"time\", \"datetime_value\", \"code\", \"numeric_value\")\n",
    "\n",
    "print(\"\\nTransforming clinical event tables...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "clinical_meds = {}\n",
    "clinical_tables = [\n",
    "    'visit_occurrence', \n",
    "    'condition_occurrence', \n",
    "    'drug_exposure',\n",
    "    'procedure_occurrence', \n",
    "    'measurement'\n",
    "]\n",
    "\n",
    "for table_name in clinical_tables:\n",
    "    if table_name in omop_tables:\n",
    "        # Handle visit_occurrence separately (no visit join needed)\n",
    "        if table_name == 'visit_occurrence':\n",
    "            df = omop_tables[table_name]\n",
    "            df = df.withColumn(\"time\", F.col(\"VISIT_START_DATETIME\").cast(\"timestamp\"))\n",
    "            df = df.withColumn(\"datetime_value\", F.col(\"VISIT_START_DATETIME\").cast(\"timestamp\"))\n",
    "            \n",
    "            # Map visit concept\n",
    "            concept_map_df = spark.createDataFrame(\n",
    "                [(k, v) for k, v in concept_map.items()],\n",
    "                [\"concept_id\", \"code\"]\n",
    "            )\n",
    "            df = df.join(\n",
    "                F.broadcast(concept_map_df),\n",
    "                df[\"VISIT_CONCEPT_ID\"] == concept_map_df[\"concept_id\"],\n",
    "                \"left\"\n",
    "            )\n",
    "            df = df.withColumn(\"numeric_value\", F.lit(None).cast(\"float\"))\n",
    "            clinical_meds[table_name] = df.select(\"PERSON_ID\", \"time\", \"datetime_value\", \"code\", \"numeric_value\")\n",
    "        else:\n",
    "            clinical_meds[table_name] = transform_clinical_table(\n",
    "                omop_tables[table_name],\n",
    "                table_name,\n",
    "                omop_tables['visit_occurrence'],\n",
    "                concept_map\n",
    "            )\n",
    "        \n",
    "        count = clinical_meds[table_name].count()\n",
    "        logger.info(f\"Transformed {table_name}: {count:,} events\")\n",
    "\n",
    "print(f\"\\nTransformed {len(clinical_meds)} clinical tables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Combine All Events\n",
    "\n",
    "Union all transformed tables into a single MEDS dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCombining all events into MEDS format...\")\n",
    "\n",
    "# Collect all DataFrames\n",
    "all_events = [person_meds] + list(clinical_meds.values())\n",
    "\n",
    "# Union all events\n",
    "from functools import reduce\n",
    "meds_df = reduce(DataFrame.union, all_events)\n",
    "\n",
    "initial_count = meds_df.count()\n",
    "logger.info(f\"Combined dataset: {initial_count:,} total events\")\n",
    "\n",
    "print(f\"\\nTotal events before cleaning: {initial_count:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Temporal Validation and Cleaning\n",
    "\n",
    "Apply temporal consistency checks to the MEDS data.\n",
    "\n",
    "### Validation Rules Applied:\n",
    "\n",
    "1. **Birth Date Validation**: Remove events that occur before patient birth\n",
    "2. **Datetime Consistency**: Ensure datetime_value is not before time\n",
    "3. **Temporal Ordering**: Correct datetime values that exceed next event time\n",
    "\n",
    "These rules ensure the data maintains logical temporal consistency for time-series modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_person_birthdate() -> DataFrame:\n",
    "    \"\"\"Prepare person birthdates for validation.\"\"\"\n",
    "    person_df = omop_tables['person']\n",
    "    \n",
    "    return person_df.withColumn(\n",
    "        \"birthdate\",\n",
    "        F.to_timestamp(\n",
    "            F.concat_ws(\n",
    "                '-',\n",
    "                F.col(\"YEAR_OF_BIRTH\"),\n",
    "                F.lpad(F.coalesce(F.col(\"MONTH_OF_BIRTH\"), F.lit(1)), 2, '0'),\n",
    "                F.lpad(F.coalesce(F.col(\"DAY_OF_BIRTH\"), F.lit(1)), 2, '0')\n",
    "            ),\n",
    "            \"yyyy-MM-dd\"\n",
    "        )\n",
    "    ).select(\"PERSON_ID\", \"birthdate\")\n",
    "\n",
    "def apply_temporal_validations(df: DataFrame, person_birthdate_df: DataFrame) -> DataFrame:\n",
    "    \"\"\"Apply temporal consistency checks.\"\"\"\n",
    "    # Join with birthdates\n",
    "    df = df.join(person_birthdate_df, on=\"PERSON_ID\", how=\"inner\")\n",
    "    \n",
    "    # Rule 1: Filter events before birth\n",
    "    before_filter = df.count()\n",
    "    df = df.filter(F.col(\"time\") >= F.col(\"birthdate\"))\n",
    "    after_filter = df.count()\n",
    "    logger.info(f\"Removed {before_filter - after_filter:,} events before birth\")\n",
    "    \n",
    "    # Rule 2: Ensure datetime_value is not before time\n",
    "    df = df.withColumn(\n",
    "        \"datetime_value\",\n",
    "        F.when(\n",
    "            F.col(\"datetime_value\") < F.col(\"time\"),\n",
    "            F.col(\"time\")\n",
    "        ).otherwise(F.col(\"datetime_value\"))\n",
    "    )\n",
    "    \n",
    "    # Rule 3: Handle temporal ordering between events\n",
    "    window_spec = Window.partitionBy(\"PERSON_ID\").orderBy(\"time\")\n",
    "    df = df.withColumn(\"next_event_time\", F.lead(\"time\").over(window_spec))\n",
    "    \n",
    "    df = df.withColumn(\n",
    "        \"datetime_value\",\n",
    "        F.when(\n",
    "            (F.col(\"next_event_time\").isNotNull()) & \n",
    "            (F.col(\"datetime_value\") > F.col(\"next_event_time\")),\n",
    "            F.col(\"time\")\n",
    "        ).otherwise(F.col(\"datetime_value\"))\n",
    "    )\n",
    "    \n",
    "    # Remove temporary columns\n",
    "    return df.drop(\"next_event_time\", \"birthdate\")\n",
    "\n",
    "print(\"\\nApplying temporal validations...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "person_birthdate = prepare_person_birthdate()\n",
    "meds_df = apply_temporal_validations(meds_df, person_birthdate)\n",
    "\n",
    "final_count = meds_df.count()\n",
    "records_removed = initial_count - final_count\n",
    "retention_rate = (final_count / initial_count * 100) if initial_count > 0 else 0\n",
    "\n",
    "print(f\"\\nTemporal Validation Results:\")\n",
    "print(f\"  Events before: {initial_count:,}\")\n",
    "print(f\"  Events after: {final_count:,}\")\n",
    "print(f\"  Records removed: {records_removed:,}\")\n",
    "print(f\"  Retention rate: {retention_rate:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Export MEDS Data\n",
    "\n",
    "Save the final MEDS dataset to Parquet format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nExporting MEDS data...\")\n",
    "\n",
    "# Write to Parquet\n",
    "output_file = f\"{OUTPUT_PATH}meds_data\"\n",
    "meds_df.write.mode(\"overwrite\").parquet(output_file, compression='snappy')\n",
    "\n",
    "print(f\"\\nâœ“ MEDS data exported to: {output_file}\")\n",
    "print(f\"  Total events: {final_count:,}\")\n",
    "print(f\"  Unique patients: {meds_df.select('PERSON_ID').distinct().count():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Verify Output\n",
    "\n",
    "Load and inspect a sample of the MEDS data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nVerifying MEDS output...\")\n",
    "\n",
    "# Load back the data\n",
    "verification_df = spark.read.schema(MEDS_SCHEMA).parquet(output_file)\n",
    "\n",
    "print(\"\\nMEDS Schema:\")\n",
    "verification_df.printSchema()\n",
    "\n",
    "print(\"\\nSample Records:\")\n",
    "verification_df.show(10, truncate=False)\n",
    "\n",
    "print(\"\\nData Statistics:\")\n",
    "print(f\"  Total events: {verification_df.count():,}\")\n",
    "print(f\"  Unique patients: {verification_df.select('PERSON_ID').distinct().count():,}\")\n",
    "print(f\"  Unique codes: {verification_df.select('code').distinct().count():,}\")\n",
    "print(f\"  Date range: {verification_df.agg(F.min('time')).collect()[0][0]} to {verification_df.agg(F.max('time')).collect()[0][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary of ETL Process\n",
    "\n",
    "### Transformation Logic\n",
    "\n",
    "**Person Table â†’ Birth Events**\n",
    "- Constructed birth date from year/month/day components\n",
    "- Assigned standardized birth code (SNOMED/184099003)\n",
    "- Set time = birth date\n",
    "\n",
    "**Clinical Tables â†’ Medical Events**\n",
    "- Joined with visit_occurrence for temporal alignment\n",
    "- Set time = visit start datetime\n",
    "- Preserved original event datetime in datetime_value\n",
    "- Mapped concept IDs to VOCABULARY/CODE format\n",
    "- Extracted numeric values for measurements\n",
    "\n",
    "### Temporal Alignment Rationale\n",
    "\n",
    "All clinical events were aligned to their associated visit's start time. This approach:\n",
    "- Creates consistent temporal ordering\n",
    "- Simplifies sequential modeling\n",
    "- Reduces temporal granularity for privacy\n",
    "- Preserves original timing in datetime_value field\n",
    "\n",
    "### Validation Rules\n",
    "\n",
    "Three temporal consistency rules were applied:\n",
    "\n",
    "1. **Events must occur after birth**: Removed events before patient birth date\n",
    "2. **Datetime consistency**: Corrected datetime_value when before time\n",
    "3. **Event ordering**: Adjusted datetime values that exceeded next event time\n",
    "\n",
    "These rules ensure temporal consistency for time-series analysis.\n",
    "\n",
    "### Output Format\n",
    "\n",
    "The MEDS dataset contains:\n",
    "- Time-series events for each patient\n",
    "- Standardized medical codes (VOCABULARY/CODE format)\n",
    "- Temporal alignment to visit times\n",
    "- Numeric measurements preserved\n",
    "- Valid temporal ordering\n",
    "\n",
    "### Key Decisions\n",
    "\n",
    "**What Was Transformed:**\n",
    "- OMOP table structure â†’ MEDS time-series format\n",
    "- Concept IDs â†’ Vocabulary codes\n",
    "- Event datetimes â†’ Visit-aligned times\n",
    "\n",
    "**What Was Preserved:**\n",
    "- Original event datetimes (in datetime_value)\n",
    "- Numeric measurement values\n",
    "- All concept mappings\n",
    "- Patient identifiers\n",
    "\n",
    "**What Was Removed:**\n",
    "- Events before patient birth\n",
    "- Events with invalid temporal ordering\n",
    "- Records without valid person IDs\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
